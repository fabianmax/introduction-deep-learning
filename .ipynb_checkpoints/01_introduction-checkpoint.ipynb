{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Chapter 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Rosenblatt's Perceptron\n",
    "\n",
    "The **perceptron** was the first type of a artificial neuron introduced by [Frank Rosenblatt][1] in the late 1950. It's design was inspired by the McCulloch-Pitts model of a neuron. While perceptrons nowadays were replaced by other types of neurons, their basic design continues to exist in modern neural networks. \n",
    "\n",
    "A perceptron can be used to learn a *linearly separable* classification task. It takes **inputs** ${[x_1, x_2, ..., x_n]}$ and computes a binary output $y_i$. The **weights** ${[w_1, w_2, ..., w_n]}$ express the importance of the respective inputs to the output. The output is calculated as a weightes sum over the inputs:\n",
    "\n",
    "$$y_i = \\sum_{i}w_i x_i$$\n",
    "\n",
    "[1]: http://www.ling.upenn.edu/courses/cogs501/Rosenblatt1958.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "caption": "somecaption",
    "label": "fig:somelabel",
    "widefigure": true
   },
   "source": [
    "![Perceptron](00_ressources/img/chapter_1/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ensure that $y_i$ is a binary outcome, the perceptron uses a *step-function* with an estimated *threshold* also called **bias**:\n",
    "\n",
    "$$y_i = \n",
    "\\begin{cases}\n",
    "    0 &\\text{if $w \\cdot x+b \\leq 0$}\\cr  \n",
    "    1 &\\text{if $w \\cdot x+b \\geq 0$}\n",
    "\\end{cases}$$\n",
    "\n",
    "where $w \\cdot x \\equiv \\sum_{i}w_i x_i$ is the *dot product* between $x$ and $w$ and $b$ is the threshold.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "caption": "somecaption",
    "label": "fig:somelabel",
    "widefigure": true
   },
   "source": [
    "![Stepfunction](00_ressources/img/chapter_1/step_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the perceptron learns by iteratively updating the weight vector $w$ in the following way:\n",
    "\n",
    "$$w \\leftarrow \\dot{w} + \\nu \\cdot (y_i - \\hat{y_i}) \\cdot x_i $$\n",
    "\n",
    "where \\dot{w} is the new weight vector, $\\nu$ is a *learning rate*, $(y_i - \\hat{y_i})$ is the error in the current iteration and is the current input $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: -0.108 -> 0 | 0\n",
      "1: 0.841 -> 1 | 1\n",
      "2: 0.861 -> 1 | 1\n",
      "3: 1.81 -> 1 | 1\n"
     ]
    }
   ],
   "source": [
    "# Coding Rosenblatt's Perceptron from scratch\n",
    "# -------------------------------------------\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "# Step function\n",
    "def unit_step(x):\n",
    "    if x < 0:\n",
    "        return(0)\n",
    "    else:\n",
    "        return(1)\n",
    "\n",
    "# Data\n",
    "X = np.array([[0,0,1], \n",
    "              [0,1,1], \n",
    "              [1,0,1], \n",
    "              [1,1,1]]\n",
    "            )\n",
    "# Label\n",
    "y = np.array([0,1,1,1])\n",
    "\n",
    "w = np.random.rand(3) # Weights\n",
    "errors = []           # Errors\n",
    "eta = 0.2             # Learning rate\n",
    "n = 100               # Epochs\n",
    "\n",
    "# Training\n",
    "for i in range(n):\n",
    "    # Get row index\n",
    "    index = random.randint(0,3)\n",
    "    # Define minibatch (online)\n",
    "    x_batch = X[index,:]\n",
    "    y_batch = y[index]\n",
    "    # Calculate activation\n",
    "    y_hat = unit_step(np.dot(w, x_batch))\n",
    "    # Caluclate error\n",
    "    error = y_batch - y_hat\n",
    "    errors.append(error)\n",
    "    # Update weights\n",
    "    w += eta * error * x_batch\n",
    "\n",
    "# Prediction  \n",
    "for index, x in enumerate(X):\n",
    "    y_hat = np.dot(x, w)\n",
    "    print(\"{}: {} -> {} | {}\".format(index, round(y_hat, 3), unit_step(y_hat), y[index]))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
